{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad80f8bb-d660-4356-9ac2-af2149008e1f",
   "metadata": {},
   "source": [
    "# ðŸ Python ðŸ“„ Detecting Duplicates in Large Volumes of Text with fuzzywuzzy\n",
    "\n",
    "## â“ Have you ever tried to clean up a large dataset full of duplicated text? Itâ€™s frustrating, right? ðŸ¤¯ Let's solve this once and for all!\n",
    "\n",
    "ðŸ‘‰ **Solution:** Use Python's `df[\"text\"].duplicated()` and `fuzzywuzzy` to efficiently detect similar texts in a dataset.\n",
    "\n",
    "## ðŸ”§ How does it work?\n",
    "\n",
    "- `duplicated()`: This function checks for exact duplicate entries in your dataset.\n",
    "- `fuzzywuzzy`: Measures text similarity using Levenshtein distance, which allows you to find non-exact matches (fuzzy duplicates).\n",
    "\n",
    "## ðŸ”Ž Why does this matter? \n",
    "Handling text data often involves large amounts of information. Without proper cleaning, duplicates can significantly affect data quality, leading to inaccurate models and decisions. ðŸ§  By detecting duplicates efficiently, we can improve the quality of knowledge bases and social media feeds.\n",
    "\n",
    "## âœ¨ Real Example:\n",
    "Imagine you work with large text datasets from social media and need to clean up duplicate comments that are written slightly differently. By using these methods, you can find and remove similar but non-identical comments, streamlining the data for further analysis.\n",
    "\n",
    "## âš™ï¸ Business Impact:\n",
    "\n",
    "ðŸŽ¯ **Faster Data Processing**: Reduces the time spent on data cleaning.  \n",
    "ðŸŒ **Better Insights**: Improves the accuracy of models and predictions.  \n",
    "ðŸš€ **Optimized Knowledge Management**: Helps maintain clean datasets, improving the effectiveness of AI systems.\n",
    "\n",
    "## ðŸ“Š Code Overview:\n",
    "The code uses `fuzzywuzzy` to compare the similarity of text entries in a dataset and remove near-duplicate values based on a similarity threshold. This helps you clean large volumes of unstructured data efficiently.\n",
    "\n",
    "## ðŸ’­ Reflection:\n",
    "How would you handle data cleaning in your work with large-scale text data? ðŸ¤”\n",
    "\n",
    "ðŸ”— [Github](https://github.com/jcombari/AI-For-Unstructured-Data/tree/main)\n",
    "\n",
    "ðŸ”‘ #DataScience #MachineLearning #AI #DataCleaning #TextMining #Python #FuzzyWuzzy #UnstructuredData #TechForAll #DataScienceTips #KnowledgeManagement #DataQuality #ScienceCommunicator #PythonExperts\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ Python ðŸ“„ Detectar duplicados en grandes volÃºmenes de texto con fuzzywuzzy\n",
    "\n",
    "## â“ Â¿Alguna vez has intentado limpiar un conjunto de datos masivo lleno de textos duplicados? Â¡Es frustrante, verdad? ðŸ¤¯ Â¡Vamos a solucionarlo de una vez por todas!\n",
    "\n",
    "ðŸ‘‰ **SoluciÃ³n:** Usa `df[\"text\"].duplicated()` y `fuzzywuzzy` para detectar de manera eficiente textos similares en un conjunto de datos.\n",
    "\n",
    "## ðŸ”§ Â¿CÃ³mo funciona?\n",
    "\n",
    "- `duplicated()`: Esta funciÃ³n busca entradas exactas duplicadas en tu conjunto de datos.\n",
    "- `fuzzywuzzy`: Mide la similitud de los textos usando la distancia de Levenshtein, lo que te permite encontrar coincidencias no exactas (duplicados difusos).\n",
    "\n",
    "## ðŸ”Ž Â¿Por quÃ© importa esto?\n",
    "Trabajar con datos de texto suele implicar grandes volÃºmenes de informaciÃ³n. Si no se limpia adecuadamente, los duplicados pueden afectar la calidad de los datos, llevando a modelos y decisiones imprecisas. ðŸ§  Detectando duplicados de manera eficiente, podemos mejorar la calidad de las bases de conocimiento y los feeds en redes sociales.\n",
    "\n",
    "## âœ¨ Ejemplo Real:\n",
    "Imagina que trabajas con grandes conjuntos de datos de redes sociales y necesitas limpiar los comentarios duplicados que estÃ¡n escritos de manera ligeramente diferente. Usando estos mÃ©todos, puedes encontrar y eliminar comentarios similares, agilizando los datos para anÃ¡lisis posteriores.\n",
    "\n",
    "## âš™ï¸ Impacto en el negocio:\n",
    "\n",
    "ðŸŽ¯ **Procesamiento de Datos MÃ¡s RÃ¡pido**: Reduce el tiempo dedicado a la limpieza de datos.  \n",
    "ðŸŒ **Mejores Perspectivas**: Mejora la precisiÃ³n de modelos y predicciones.  \n",
    "ðŸš€ **GestiÃ³n de Conocimiento Optimizada**: Ayuda a mantener conjuntos de datos limpios, mejorando la efectividad de los sistemas de IA.\n",
    "\n",
    "## ðŸ“Š Resumen del CÃ³digo:\n",
    "El cÃ³digo utiliza `fuzzywuzzy` para comparar la similitud de las entradas de texto en un conjunto de datos y eliminar los valores casi duplicados basados en un umbral de similitud. Esto ayuda a limpiar grandes volÃºmenes de datos no estructurados de manera eficiente.\n",
    "\n",
    "## ðŸ’­ ReflexiÃ³n:\n",
    "Â¿CÃ³mo manejarÃ­as la limpieza de datos en tu trabajo con grandes volÃºmenes de datos textuales? ðŸ¤”\n",
    "\n",
    "ðŸ”— [Github](https://github.com/jcombari/AI-For-Unstructured-Data/tree/main)\n",
    "\n",
    "ðŸ”‘ #CienciaDeDatos #AprendizajeAutomÃ¡tico #IA #LimpiezaDeDatos #MinerÃ­aDeTexto #Python #FuzzyWuzzy #DatosNoEstructurados #TecnologÃ­aParaTodos #ConsejosDeDatos #GestiÃ³nDeConocimiento #CalidadDeDatos #ScienceCommunicator #ExpertosEnPython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a621de66-572f-4acd-8376-1711c5898d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact duplicates detected:\n",
      "                       text  exact_duplicates\n",
      "0      I love data science!             False\n",
      "1  Data science is amazing!             False\n",
      "2      I love data science!              True\n",
      "3       Data science rocks!             False\n",
      "4      Data Science is life             False\n",
      "\n",
      "Fuzzy matches found:\n",
      "Text: I love data science! - Similar to: Data Science is life with score 83\n",
      "Text: Data science is amazing! - Similar to: Data Science is life with score 82\n",
      "Text: I love data science! - Similar to: Data Science is life with score 83\n",
      "Text: Data Science is life - Similar to: I love data science! with score 83\n",
      "Text: Data Science is life - Similar to: I love data science! with score 83\n",
      "Text: Data Science is life - Similar to: Data science is amazing! with score 82\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Example dataset with some similar and duplicate text\n",
    "data = {'text': ['I love data science!', \n",
    "                 'Data science is amazing!', \n",
    "                 'I love data science!', \n",
    "                 'Data science rocks!', \n",
    "                 'Data Science is life']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Detect exact duplicates in the text column\n",
    "df['exact_duplicates'] = df['text'].duplicated()\n",
    "\n",
    "# Function to detect fuzzy duplicates based on a similarity threshold\n",
    "def fuzzy_duplicates(df, column_name, threshold=80):\n",
    "    # Create a list of text values in the column\n",
    "    texts = df[column_name].tolist()\n",
    "    fuzzy_matches = []\n",
    "    \n",
    "    # Compare each text with every other text\n",
    "    for i, text in enumerate(texts):\n",
    "        matches = process.extract(text, texts, limit=None)\n",
    "        \n",
    "        # Check if any match has a similarity score above the threshold\n",
    "        for match in matches:\n",
    "            if match[1] >= threshold and match[0] != text:\n",
    "                fuzzy_matches.append((i, match[0], match[1]))\n",
    "    \n",
    "    return fuzzy_matches\n",
    "\n",
    "# Detect fuzzy duplicates\n",
    "fuzzy_matches = fuzzy_duplicates(df, 'text', threshold=80)\n",
    "\n",
    "# Display the results\n",
    "print(\"Exact duplicates detected:\")\n",
    "print(df)\n",
    "print(\"\\nFuzzy matches found:\")\n",
    "for match in fuzzy_matches:\n",
    "    print(f\"Text: {df['text'][match[0]]} - Similar to: {match[1]} with score {match[2]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "702dfe0d-f36a-4d5a-8e65-79a2b948aff5",
   "metadata": {},
   "source": [
    "# ğŸ Python | Automatically Download YouTube Subtitles ğŸ“\n",
    "\n",
    "## â“Ever wanted to grab subtitles from a video to study languages, summarize content, or boost accessibility?\n",
    "\n",
    "## ğŸ‘‰ With `youtube_dl` and `pysrt`, it's just a few lines of code away!\n",
    "\n",
    "## ğŸ”§ How does it work?\n",
    "(à¹‘â€¢Ì€ã…‚â€¢Ì)Ùˆâœ§ We fetch the captions from a YouTube link and convert them into plain text you can analyze, translate, or feed into your NLP projects.\n",
    "\n",
    "## ğŸ” Why does it matter?\n",
    "(ï½¡â™¥â€¿â™¥ï½¡) This approach enables:\n",
    "â€¢âœï¸ Automatic dataset generation from video content.  \n",
    "â€¢ğŸŒ Better accessibility and language learning.  \n",
    "â€¢ğŸ§  Trend analysis from educational or scientific media.\n",
    "\n",
    "## âœ¨ Real-world example:\n",
    "Letâ€™s say you want to study how AI is taught online. You download subtitles from 10 top YouTube videos, clean the text, analyze it for patterns and keywords. VoilÃ ! A real-world dataset for your next NLP model ğŸŒ\n",
    "\n",
    "## âš™ï¸ Business impact:\n",
    "â€¢ğŸ“ˆ Speeds up educational content generation.  \n",
    "â€¢ğŸ¦¾ Powers real-world NLP model training.  \n",
    "â€¢ğŸ’¬ Enhances multilingual customer support.\n",
    "\n",
    "## ğŸ“Š Code summary:\n",
    "â€¢ğŸ¥ Download `.srt` subtitles from YouTube.  \n",
    "â€¢ğŸ§½ Clean and format subtitle content.  \n",
    "â€¢ğŸ”  Extract top keywords with `sklearn`.\n",
    "\n",
    "ğŸ”— [Github](https://github.com/jcombari/AI-For-Unstructured-Data/tree/main)\n",
    "\n",
    "ğŸ’­ Reflection:\n",
    "How would you use video subtitles in your AI or data workflows? ğŸ“\n",
    "\n",
    "ğŸ”‘ #datascience #python #youtube #machinelearning #nlp #ai #deeplearning #generativeai #education #accessibility #neurodiversity #openai #upskilling #techtok #youngscientists\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ Python | Descarga subtÃ­tulos de YouTube automÃ¡ticamente ğŸ“\n",
    "\n",
    "## â“Â¿Alguna vez quisiste extraer subtÃ­tulos de un video para estudiar idiomas, hacer resÃºmenes rÃ¡pidos o mejorar la accesibilidad de tu contenido?\n",
    "\n",
    "## ğŸ‘‰ Â¡Puedes hacerlo en segundos con `youtube_dl` y `pysrt`!\n",
    "\n",
    "## ğŸ”§ Â¿CÃ³mo funciona?\n",
    "(à¹‘â€¢Ì€ã…‚â€¢Ì)Ùˆâœ§ Descargamos los subtÃ­tulos directamente desde un enlace de YouTube y los transformamos en texto legible que puedes analizar, traducir o reutilizar en otro proyecto de NLP.\n",
    "\n",
    "## ğŸ” Â¿Por quÃ© importa?\n",
    "(ï½¡â™¥â€¿â™¥ï½¡) Esta tÃ©cnica permite:\n",
    "â€¢âœï¸ Crear datasets automÃ¡ticamente a partir de contenido audiovisual.  \n",
    "â€¢ğŸŒ Usarlo como herramienta de accesibilidad o educaciÃ³n.  \n",
    "â€¢ğŸ§  Analizar tendencias en videos de formaciÃ³n o divulgaciÃ³n cientÃ­fica.\n",
    "\n",
    "## âœ¨ Ejemplo real o Caso prÃ¡ctico:\n",
    "SupÃ³n que quieres estudiar cÃ³mo se enseÃ±a IA en YouTube. Descargas 10 videos populares, extraes sus subtÃ­tulos, limpias el texto, y lo analizas con NLP. Â¡Boom! Dataset curado, accesible y directo desde la web ğŸŒ\n",
    "\n",
    "## âš™ï¸ Impacto en el negocio:\n",
    "â€¢ğŸ“ˆ AutomatizaciÃ³n en la creaciÃ³n de contenido educativo.  \n",
    "â€¢ğŸ¦¾ Entrenamiento de modelos NLP con datos del mundo real.  \n",
    "â€¢ğŸ’¬ Mejora en las estrategias de atenciÃ³n al cliente multilingÃ¼e.\n",
    "\n",
    "## ğŸ“Š Resumen de quÃ© se hace en el cÃ³digo:\n",
    "â€¢ğŸ¥ Descargamos subtÃ­tulos en `.srt` desde un enlace.  \n",
    "â€¢ğŸ§½ Limpiamos el texto de marcas de tiempo.  \n",
    "â€¢ğŸ”  Creamos un resumen de palabras clave con `sklearn`.\n",
    "\n",
    "ğŸ”— [Github](https://github.com/jcombari/AI-For-Unstructured-Data/tree/main)\n",
    "\n",
    "ğŸ’­ ReflexiÃ³n:\n",
    "Â¿CÃ³mo aprovecharÃ­as los subtÃ­tulos de video en tus proyectos de IA o anÃ¡lisis de datos? ğŸ“\n",
    "\n",
    "ğŸ”‘ Hashtags:\n",
    "#datascience #python #youtube #machinelearning #nlp #ai #deeplearning #generativeai #education #accessibility #neurodiversity #openai #upskilling #techtok #youngscientists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b387243c-6e65-46a3-abc2-fa36c0b14fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pysrt\n",
    "import yt_dlp\n",
    "import webvtt  # Needed to convert .vtt to .srt format\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# URL of the YouTube video\n",
    "video_url = 'https://www.youtube.com/watch?v=2lAe1cqCOXo'\n",
    "\n",
    "# 1. Extract metadata to check available subtitle languages\n",
    "ydl_opts_info = {\n",
    "    'skip_download': True,\n",
    "    'quiet': True,\n",
    "    'no_warnings': True\n",
    "}\n",
    "with yt_dlp.YoutubeDL(ydl_opts_info) as ydl:\n",
    "    info = ydl.extract_info(video_url, download=False)\n",
    "    video_id = info.get('id', 'video')\n",
    "    subs = info.get('subtitles', {})  # Manual subtitles\n",
    "    auto_subs = info.get('automatic_captions', {})  # Auto-generated subtitles\n",
    "\n",
    "# Merge both subtitle dictionaries\n",
    "all_subs = {**subs, **auto_subs}\n",
    "\n",
    "# Show available languages\n",
    "print(\"ğŸ—£ï¸ Available subtitle languages:\")\n",
    "for lang_code in all_subs.keys():\n",
    "    print(f\" - {lang_code}\")\n",
    "\n",
    "# 2. Download English subtitles (preferably .vtt format)\n",
    "download_opts = {\n",
    "    'skip_download': True,\n",
    "    'quiet': True,\n",
    "    'no_warnings': True,\n",
    "    'writesubtitles': True,\n",
    "    'writeautomaticsub': True,\n",
    "    'subtitleslangs': ['en'],\n",
    "    'subtitlesformat': 'vtt',\n",
    "    'outtmpl': f'{video_id}.%(ext)s'\n",
    "}\n",
    "with yt_dlp.YoutubeDL(download_opts) as ydl:\n",
    "    ydl.download([video_url])\n",
    "\n",
    "# 3. Convert .vtt to .srt if necessary\n",
    "vtt_file = f'{video_id}.en.vtt'\n",
    "srt_file = f'{video_id}.en.srt'\n",
    "\n",
    "if os.path.exists(vtt_file):\n",
    "    webvtt.read(vtt_file).save_as_srt(srt_file)\n",
    "    print(f\"âœ… Converted {vtt_file} to {srt_file}\")\n",
    "\n",
    "# 4. Read and clean subtitle text\n",
    "subs = pysrt.open(srt_file)\n",
    "full_text = \" \".join([sub.text for sub in subs])  # Join all subtitle lines\n",
    "cleaned_text = re.sub(r'\\[.*?\\]|[^\\w\\s]', '', full_text)  # Remove punctuation and tags\n",
    "\n",
    "# 5. Extract top keywords using bag-of-words model\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=10)\n",
    "X = vectorizer.fit_transform([cleaned_text])\n",
    "keywords = vectorizer.get_feature_names_out()\n",
    "counts = X.toarray().flatten()\n",
    "\n",
    "# 6. Plot the top keywords\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(keywords, counts, color='orange')\n",
    "plt.title('Top Keywords from English YouTube Subtitles')  # No emoji to avoid font warnings\n",
    "plt.xlabel('Keywords')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "702dfe0d-f36a-4d5a-8e65-79a2b948aff5",
   "metadata": {},
   "source": [
    "# 🐍 Python | Automatically Download YouTube Subtitles 📝\n",
    "\n",
    "## ❓Ever wanted to grab subtitles from a video to study languages, summarize content, or boost accessibility?\n",
    "\n",
    "## 👉 With `youtube_dl` and `pysrt`, it's just a few lines of code away!\n",
    "\n",
    "## 🔧 How does it work?\n",
    "(๑•̀ㅂ•́)و✧ We fetch the captions from a YouTube link and convert them into plain text you can analyze, translate, or feed into your NLP projects.\n",
    "\n",
    "## 🔎 Why does it matter?\n",
    "(｡♥‿♥｡) This approach enables:\n",
    "•✍️ Automatic dataset generation from video content.  \n",
    "•🌐 Better accessibility and language learning.  \n",
    "•🧠 Trend analysis from educational or scientific media.\n",
    "\n",
    "## ✨ Real-world example:\n",
    "Let’s say you want to study how AI is taught online. You download subtitles from 10 top YouTube videos, clean the text, analyze it for patterns and keywords. Voilà! A real-world dataset for your next NLP model 🌍\n",
    "\n",
    "## ⚙️ Business impact:\n",
    "•📈 Speeds up educational content generation.  \n",
    "•🦾 Powers real-world NLP model training.  \n",
    "•💬 Enhances multilingual customer support.\n",
    "\n",
    "## 📊 Code summary:\n",
    "•🎥 Download `.srt` subtitles from YouTube.  \n",
    "•🧽 Clean and format subtitle content.  \n",
    "•🔠 Extract top keywords with `sklearn`.\n",
    "\n",
    "🔗 [Github](https://github.com/jcombari/AI-For-Unstructured-Data/tree/main)\n",
    "\n",
    "💭 Reflection:\n",
    "How would you use video subtitles in your AI or data workflows? 🎓\n",
    "\n",
    "🔑 #datascience #python #youtube #machinelearning #nlp #ai #deeplearning #generativeai #education #accessibility #neurodiversity #openai #upskilling #techtok #youngscientists\n",
    "\n",
    "---\n",
    "\n",
    "# 🐍 Python | Descarga subtítulos de YouTube automáticamente 📝\n",
    "\n",
    "## ❓¿Alguna vez quisiste extraer subtítulos de un video para estudiar idiomas, hacer resúmenes rápidos o mejorar la accesibilidad de tu contenido?\n",
    "\n",
    "## 👉 ¡Puedes hacerlo en segundos con `youtube_dl` y `pysrt`!\n",
    "\n",
    "## 🔧 ¿Cómo funciona?\n",
    "(๑•̀ㅂ•́)و✧ Descargamos los subtítulos directamente desde un enlace de YouTube y los transformamos en texto legible que puedes analizar, traducir o reutilizar en otro proyecto de NLP.\n",
    "\n",
    "## 🔎 ¿Por qué importa?\n",
    "(｡♥‿♥｡) Esta técnica permite:\n",
    "•✍️ Crear datasets automáticamente a partir de contenido audiovisual.  \n",
    "•🌐 Usarlo como herramienta de accesibilidad o educación.  \n",
    "•🧠 Analizar tendencias en videos de formación o divulgación científica.\n",
    "\n",
    "## ✨ Ejemplo real o Caso práctico:\n",
    "Supón que quieres estudiar cómo se enseña IA en YouTube. Descargas 10 videos populares, extraes sus subtítulos, limpias el texto, y lo analizas con NLP. ¡Boom! Dataset curado, accesible y directo desde la web 🌍\n",
    "\n",
    "## ⚙️ Impacto en el negocio:\n",
    "•📈 Automatización en la creación de contenido educativo.  \n",
    "•🦾 Entrenamiento de modelos NLP con datos del mundo real.  \n",
    "•💬 Mejora en las estrategias de atención al cliente multilingüe.\n",
    "\n",
    "## 📊 Resumen de qué se hace en el código:\n",
    "•🎥 Descargamos subtítulos en `.srt` desde un enlace.  \n",
    "•🧽 Limpiamos el texto de marcas de tiempo.  \n",
    "•🔠 Creamos un resumen de palabras clave con `sklearn`.\n",
    "\n",
    "🔗 [Github](https://github.com/jcombari/AI-For-Unstructured-Data/tree/main)\n",
    "\n",
    "💭 Reflexión:\n",
    "¿Cómo aprovecharías los subtítulos de video en tus proyectos de IA o análisis de datos? 🎓\n",
    "\n",
    "🔑 Hashtags:\n",
    "#datascience #python #youtube #machinelearning #nlp #ai #deeplearning #generativeai #education #accessibility #neurodiversity #openai #upskilling #techtok #youngscientists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b387243c-6e65-46a3-abc2-fa36c0b14fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pysrt\n",
    "import yt_dlp\n",
    "import webvtt  # Needed to convert .vtt to .srt format\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# URL of the YouTube video\n",
    "video_url = 'https://www.youtube.com/watch?v=2lAe1cqCOXo'\n",
    "\n",
    "# 1. Extract metadata to check available subtitle languages\n",
    "ydl_opts_info = {\n",
    "    'skip_download': True,\n",
    "    'quiet': True,\n",
    "    'no_warnings': True\n",
    "}\n",
    "with yt_dlp.YoutubeDL(ydl_opts_info) as ydl:\n",
    "    info = ydl.extract_info(video_url, download=False)\n",
    "    video_id = info.get('id', 'video')\n",
    "    subs = info.get('subtitles', {})  # Manual subtitles\n",
    "    auto_subs = info.get('automatic_captions', {})  # Auto-generated subtitles\n",
    "\n",
    "# Merge both subtitle dictionaries\n",
    "all_subs = {**subs, **auto_subs}\n",
    "\n",
    "# Show available languages\n",
    "print(\"🗣️ Available subtitle languages:\")\n",
    "for lang_code in all_subs.keys():\n",
    "    print(f\" - {lang_code}\")\n",
    "\n",
    "# 2. Download English subtitles (preferably .vtt format)\n",
    "download_opts = {\n",
    "    'skip_download': True,\n",
    "    'quiet': True,\n",
    "    'no_warnings': True,\n",
    "    'writesubtitles': True,\n",
    "    'writeautomaticsub': True,\n",
    "    'subtitleslangs': ['en'],\n",
    "    'subtitlesformat': 'vtt',\n",
    "    'outtmpl': f'{video_id}.%(ext)s'\n",
    "}\n",
    "with yt_dlp.YoutubeDL(download_opts) as ydl:\n",
    "    ydl.download([video_url])\n",
    "\n",
    "# 3. Convert .vtt to .srt if necessary\n",
    "vtt_file = f'{video_id}.en.vtt'\n",
    "srt_file = f'{video_id}.en.srt'\n",
    "\n",
    "if os.path.exists(vtt_file):\n",
    "    webvtt.read(vtt_file).save_as_srt(srt_file)\n",
    "    print(f\"✅ Converted {vtt_file} to {srt_file}\")\n",
    "\n",
    "# 4. Read and clean subtitle text\n",
    "subs = pysrt.open(srt_file)\n",
    "full_text = \" \".join([sub.text for sub in subs])  # Join all subtitle lines\n",
    "cleaned_text = re.sub(r'\\[.*?\\]|[^\\w\\s]', '', full_text)  # Remove punctuation and tags\n",
    "\n",
    "# 5. Extract top keywords using bag-of-words model\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=10)\n",
    "X = vectorizer.fit_transform([cleaned_text])\n",
    "keywords = vectorizer.get_feature_names_out()\n",
    "counts = X.toarray().flatten()\n",
    "\n",
    "# 6. Plot the top keywords\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(keywords, counts, color='orange')\n",
    "plt.title('Top Keywords from English YouTube Subtitles')  # No emoji to avoid font warnings\n",
    "plt.xlabel('Keywords')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

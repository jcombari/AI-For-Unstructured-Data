{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "128371bd-a7b7-45ad-9461-31b2a33ea6dc",
   "metadata": {},
   "source": [
    "# 🐍 Python 🖼️ Extracting Web Images with BeautifulSoup\n",
    "\n",
    "## ❓Did you know you can build your own image dataset from any website… using just a few lines of code?  \n",
    "With Python, you can automate massive image downloads for vision models, dashboards or recommender systems. 🔍\n",
    "\n",
    "## 👉 Solution  \n",
    "We use **BeautifulSoup** and `requests` to scrape a webpage, search for `<img>` tags, and download images efficiently based on criteria.\n",
    "\n",
    "## 🔧 How does it work?\n",
    "*️⃣ The script:\n",
    " ✦ Reads the page HTML  \n",
    " ✦ Finds all `<img>` tags  \n",
    " ✦ Filters them by extension  \n",
    " ✦ Saves images in a timestamped folder\n",
    "\n",
    "## 🔎 Why does it matter?\n",
    "This approach is great for:  \n",
    "📸 Creating visual datasets  \n",
    "📚 Training real-world models  \n",
    "🔗 Learning professional file & HTML manipulation\n",
    "\n",
    "## ✨ Real-life example:\n",
    "Planning to build a plant classifier?  \n",
    "Scrape hundreds of horticulture images, label them, and use ResNet or EfficientNet to classify species. 🌿\n",
    "\n",
    "## ⚙️ Business impact:\n",
    "🚀 Speed up visual data collection  \n",
    "🧠 Boost lean AI projects  \n",
    "🎯 Perfect for design, research or MVPs\n",
    "\n",
    "## 📊 What the code does:\n",
    "1️⃣ Sends a GET request to a web page  \n",
    "2️⃣ Parses HTML using BeautifulSoup  \n",
    "3️⃣ Extracts and filters images  \n",
    "4️⃣ Displays them inline in Jupyter  \n",
    "5️⃣ Saves them to a dated folder\n",
    "\n",
    "🔗[GitHub](https://github.com/jcombari/AI-For-Unstructured-Data/tree/main)\n",
    "\n",
    "💭 Reflection:  \n",
    "What kind of images would *you* automate for your next computer vision project?\n",
    "\n",
    "🔑 #Python #DataScience #WebScraping #BeautifulSoup #AI #MachineLearning #DeepLearning #ComputerVision #OpenAI #LinkedInTech\n",
    "\n",
    "---\n",
    "\n",
    "# 🐍 Python 🖼️ Extraer imágenes de una web con BeautifulSoup\n",
    "\n",
    "## ❓¿Sabías que puedes construir tu propio dataset de imágenes desde cualquier sitio web... con solo unas líneas de código?  \n",
    "Con Python puedes automatizar la descarga de imágenes para visión por computador, dashboards o sistemas de recomendación. 📦\n",
    "\n",
    "## 👉 Solución  \n",
    "Utilizamos **BeautifulSoup** y `requests` para realizar scraping de una página web, buscando etiquetas `<img>` y descargando las imágenes con filtros inteligentes.\n",
    "\n",
    "## 🔧 ¿Cómo funciona?\n",
    "*️⃣ El script:\n",
    " ✦ Lee el HTML de una web  \n",
    " ✦ Encuentra todas las etiquetas `<img>`  \n",
    " ✦ Filtra las imágenes por extensión  \n",
    " ✦ Las guarda en una carpeta local con nombre personalizado\n",
    "\n",
    "## 🔎 ¿Por qué importa?\n",
    "Esta técnica es ideal para:  \n",
    "📸 Generar datasets visuales  \n",
    "📚 Entrenar modelos con imágenes reales  \n",
    "🔗 Manipular archivos, URLs y HTML profesionalmente\n",
    "\n",
    "## ✨ Ejemplo real o caso práctico:\n",
    "¿Planeas entrenar un clasificador de plantas?  \n",
    "Descarga cientos de imágenes de horticultura, clasifícalas y usa modelos como ResNet o EfficientNet para detectar especies. 🌿\n",
    "\n",
    "## ⚙️ Impacto en el negocio:\n",
    "🚀 Ahorro de tiempo en recolección de datos visuales  \n",
    "🧠 Impulso a proyectos lean de Data Science  \n",
    "🎯 Potencial para IA, diseño o investigación de mercado\n",
    "\n",
    "## 📊 ¿Qué hace el código?\n",
    "1️⃣ Envía una solicitud GET a una URL  \n",
    "2️⃣ Analiza el HTML con BeautifulSoup  \n",
    "3️⃣ Extrae y filtra imágenes  \n",
    "4️⃣ Las muestra en Jupyter Notebook  \n",
    "5️⃣ Las guarda en una carpeta con prefijo de fecha\n",
    "\n",
    "🔗[GitHub](https://github.com/jcombari/AI-For-Unstructured-Data/tree/main)\n",
    "\n",
    "💭 Reflexión:  \n",
    "¿Y tú, qué tipo de imágenes automatizarías para tus proyectos de IA?\n",
    "\n",
    "🔑 #Python #DataScience #WebScraping #BeautifulSoup #DeepLearning #AI #VisionPorComputador #CienciaDeDatos #LinkedInTech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae09f27-a213-4760-b352-f83cdf36e183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 Import required libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from urllib.parse import urljoin\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "\n",
    "# 🌐 Target URL\n",
    "url = \"https://books.toscrape.com/catalogue/page-1.html\"\n",
    "\n",
    "# 🔁 Request HTML content\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# 📁 Prepare folder with date prefix\n",
    "date_prefix = \"20250509\"\n",
    "folder_name = f\"{date_prefix}_downloaded_images\"\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# 🖼️ Extract all image containers\n",
    "img_tags = soup.find_all(\"img\")\n",
    "\n",
    "# 🔽 Download and display images\n",
    "count = 0\n",
    "for img in img_tags:\n",
    "    img_src = img.get(\"src\")\n",
    "    if img_src:\n",
    "        # Convert relative URL to absolute\n",
    "        img_url = urljoin(url, img_src)\n",
    "\n",
    "        try:\n",
    "            # 📥 Download image content\n",
    "            img_data = requests.get(img_url).content\n",
    "            image = Image.open(BytesIO(img_data))\n",
    "\n",
    "            # 🖼️ Show image in notebook\n",
    "            display(image)\n",
    "\n",
    "            # 💾 Save locally\n",
    "            file_ext = os.path.splitext(img_url)[-1]\n",
    "            file_name = f\"{date_prefix}_img_{count}{file_ext}\"\n",
    "            path = os.path.join(folder_name, file_name)\n",
    "\n",
    "            with open(path, \"wb\") as f:\n",
    "                f.write(img_data)\n",
    "\n",
    "            count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error with {img_url}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
